{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b6d2797-8712-4a7f-a70d-0a24010bd694",
   "metadata": {},
   "source": [
    "# Q&A Part II"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd70aac2-0dd5-4baf-bb7b-f5c6335d1fa8",
   "metadata": {},
   "source": [
    "### Q: How can I track gender-based discourse? For example, a comparison of how often a female vs. male character speaks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbb6351-aa52-44cd-837e-9599367fc88a",
   "metadata": {},
   "source": [
    "A: To do this we need to: \n",
    "- Collect all words spoken by male and female characters separately\n",
    "- Calculate Word Frequencies by Gender\n",
    "- Identify Distinctive Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd4c2af0-cef6-46da-ba93-4bf715b35de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech counts by gender:\n",
      " - Male: 1168 words\n",
      " - Female: 1758 words\n",
      "\n",
      "Distinctive Male Words: {'...': 8, 'well': 9, 'christened': 12, '--': 7, 'love': 6, 'miss': 14, 'fairfax': 7, 'muffins': 13, 'eat': 7, 'ever': 6}\n",
      "Distinctive Female Words: {'.': 234, 'little': 7, 'man': 6, 'would': 11, \"'s\": 10, 'ernest': 20, 'mr.': 20, 'worthing': 19, 'think': 12, 'quite': 15, 'course': 7, 'always': 8, 'engaged': 7, 'seems': 7, 'oh': 10, 'fact': 6, 'us': 6, 'diary': 6, 'pray': 6, 'could': 6, 'much': 7, 'dear': 6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/tomvannuenen/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict, Counter\n",
    "import re\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Set of English stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Define characters and their associated genders\n",
    "genders = {\n",
    "    'ALGERNON': 'male',\n",
    "    'JACK': 'male',\n",
    "    'GWENDOLEN': 'female',\n",
    "    'CECILY': 'female',\n",
    "    'LADY BRACKNELL': 'female',\n",
    "    'MISS PRISM': 'female',\n",
    "    'LANE': 'male',\n",
    "    'MERRIMAN': 'male'\n",
    "}\n",
    "\n",
    "# Reading the play text\n",
    "file_path = '../data/1895_wilde-oscar_the-importance-of-being-earnest.txt'\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Function to parse the play into dialogues by characters\n",
    "def parse_play(text):\n",
    "    pattern = r'^([A-Z ]+):\\s*(.*)$'\n",
    "    character_dialogue = defaultdict(list)\n",
    "    for line in text.split('\\n'):\n",
    "        match = re.match(pattern, line.strip())\n",
    "        if match:\n",
    "            character, dialogue = match.groups()\n",
    "            character = character.strip()\n",
    "            if character in genders:\n",
    "                character_dialogue[character].append(dialogue.strip())\n",
    "    return character_dialogue\n",
    "\n",
    "dialogues = parse_play(text)\n",
    "\n",
    "# Initialize counters\n",
    "gendered_words = defaultdict(list)\n",
    "word_frequencies_by_gender = defaultdict(Counter)\n",
    "gender_speech_count = defaultdict(int)\n",
    "\n",
    "# Aggregate words by gender, count frequencies, and measure speech volume\n",
    "for character, speeches in dialogues.items():\n",
    "    gender = genders[character]\n",
    "    for speech in speeches:\n",
    "        words = [word.lower() for word in word_tokenize(speech) if word.lower() not in stop_words]\n",
    "        gendered_words[gender].extend(words)\n",
    "        gender_speech_count[gender] += len(words)\n",
    "\n",
    "for gender, words in gendered_words.items():\n",
    "    word_frequencies_by_gender[gender] = Counter(words)\n",
    "\n",
    "# Function to find distinctive words\n",
    "def find_distinctive_words(male_freq, female_freq, threshold=1.5):\n",
    "    distinctive_male_words = {word: count for word, count in male_freq.items()\n",
    "                              if count > threshold * female_freq.get(word, 0) and count > 5}\n",
    "    distinctive_female_words = {word: count for word, count in female_freq.items()\n",
    "                                if count > threshold * male_freq.get(word, 0) and count > 5}\n",
    "    return distinctive_male_words, distinctive_female_words\n",
    "\n",
    "distinctive_male_words, distinctive_female_words = find_distinctive_words(\n",
    "    word_frequencies_by_gender['male'], word_frequencies_by_gender['female'])\n",
    "\n",
    "print(\"Speech counts by gender:\")\n",
    "for gender, count in gender_speech_count.items():\n",
    "    print(f\" - {gender.capitalize()}: {count} words\")\n",
    "\n",
    "print(\"\\nDistinctive Male Words:\", distinctive_male_words)\n",
    "print(\"Distinctive Female Words:\", distinctive_female_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be1d5e7-58c3-4be2-b8ba-1b33f289853a",
   "metadata": {},
   "source": [
    "### Q: Can I specifically segment punctuation (question marks, exclamation points, dashes, and ellipses) by gendered speaker to understand differences in gender?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f496e391-6ddf-4f04-b042-b6d4d647f31c",
   "metadata": {},
   "source": [
    "A: To do this we adjust the script to track punctuation marks within each character's dialogue. We can focus on specific punctuation marks: question marks (?), exclamation points (!), dashes (- or —), and ellipses (...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc7faf9f-59f3-48e1-a3da-06108dabc6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Punctuation usage by gender:\n",
      " - Male: {'...': 8, '-': 27, '?': 29, '!': 21}\n",
      " - Female: {'?': 32, '!': 24, '...': 3, '-': 14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/tomvannuenen/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/tomvannuenen/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict, Counter\n",
    "import re\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Define characters and their associated genders\n",
    "genders = {\n",
    "    'ALGERNON': 'male',\n",
    "    'JACK': 'male',\n",
    "    'GWENDOLEN': 'female',\n",
    "    'CECILY': 'female',\n",
    "    'LADY BRACKNELL': 'female',\n",
    "    'MISS PRISM': 'female',\n",
    "    'LANE': 'male',\n",
    "    'MERRIMAN': 'male'\n",
    "}\n",
    "\n",
    "# Set of English stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Reading the play text\n",
    "file_path = '../data/1895_wilde-oscar_the-importance-of-being-earnest.txt'\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Function to parse the play into dialogues by characters, tracking punctuation\n",
    "def parse_play(text):\n",
    "    pattern = r'^([A-Z ]+):\\s*(.*)$'\n",
    "    character_dialogue = defaultdict(list)\n",
    "    for line in text.split('\\n'):\n",
    "        match = re.match(pattern, line.strip())\n",
    "        if match:\n",
    "            character, dialogue = match.groups()\n",
    "            character = character.strip()\n",
    "            if character in genders:\n",
    "                character_dialogue[character].append(dialogue.strip())\n",
    "    return character_dialogue\n",
    "\n",
    "dialogues = parse_play(text)\n",
    "\n",
    "# Initialize counters\n",
    "gender_punctuation_usage = defaultdict(Counter)\n",
    "\n",
    "# Punctuation of interest\n",
    "punctuations = ['?', '!', '-', '...']  # ellipses are tricky; this assumes they're well-formatted\n",
    "\n",
    "# Count punctuation by gender\n",
    "for character, speeches in dialogues.items():\n",
    "    gender = genders[character]\n",
    "    for speech in speeches:\n",
    "        # Using a simplistic method to count punctuations\n",
    "        punctuation_counts = {punct: speech.count(punct) for punct in punctuations}\n",
    "        gender_punctuation_usage[gender] += Counter(punctuation_counts)\n",
    "\n",
    "print(\"Punctuation usage by gender:\")\n",
    "for gender, counts in gender_punctuation_usage.items():\n",
    "    print(f\" - {gender.capitalize()}: {dict(counts)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b154de9d-ab5b-4d6a-94f8-1e551f140788",
   "metadata": {},
   "source": [
    "## Other Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfe5349-d174-436b-9208-4b925a6a9e80",
   "metadata": {},
   "source": [
    "### Q: Is there a way to expand collocation to include words that are frequently used in conjunction, but aren’t exactly next to each other? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bed7506c-494b-4553-9342-6d65fbe7dc09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 collocations in 'The Importance of Being Earnest' within window size 6\n",
      " - lady bracknell\n",
      " - miss prism\n",
      " - mr worthing\n",
      " - jack algernon\n",
      " - algernon cecily\n",
      " - cecily gwendolen\n",
      " - jack gwendolen\n",
      " - cecily cecily\n",
      " - gwendolen jack\n",
      " - algernon jack\n",
      " - gwendolen cecily\n",
      " - gwendolen gwendolen\n",
      " - jack well\n",
      " - algernon well\n",
      " - cecily jack\n",
      " - algernon yes\n",
      " - lane sir\n",
      " - ernest jack\n",
      " - jack lady\n",
      " - jack miss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/tomvannuenen/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/tomvannuenen/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.collocations import BigramCollocationFinder, BigramAssocMeasures\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Path to the text file of \"The Importance of Being Earnest\"\n",
    "file_path = '../data/1895_wilde-oscar_the-importance-of-being-earnest.txt'\n",
    "\n",
    "# Reading the play text\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Initialize tokenizer and stop words\n",
    "tokenizer = RegexpTokenizer(r'\\w+')  # tokenizer to remove punctuation\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Tokenize the text and remove stopwords\n",
    "tokens = [word.lower() for word in tokenizer.tokenize(text) if word.lower() not in stop_words]\n",
    "\n",
    "# Define the window size for the collocation analysis\n",
    "window_size = 6\n",
    "\n",
    "# Setup Bigram Association Measures & Finder\n",
    "measures = BigramAssocMeasures()\n",
    "finder = BigramCollocationFinder.from_words(tokens, window_size=window_size)\n",
    "\n",
    "# Filter out collocations that occur less than three times\n",
    "finder.apply_freq_filter(3)\n",
    "\n",
    "# Get the top 20 collocations based on their frequency\n",
    "collocations = finder.nbest(measures.raw_freq, 20)\n",
    "\n",
    "# Print out the collocations found\n",
    "print(f\"Top 20 collocations in 'The Importance of Being Earnest' within window size {window_size}\")\n",
    "for collocation in collocations:\n",
    "    print(f\" - {' '.join(collocation)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3866d5b-18ff-4112-b4ff-a17b8f4e3bc3",
   "metadata": {},
   "source": [
    "## Character"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a73b39e-4ec0-4a78-95ac-395fedfcd99f",
   "metadata": {},
   "source": [
    "### Q: Is there a way I can only focus on lines where three specific characters are in direct conversation with one another? How can I exclude the rest of the text?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d3818a-ef9b-47d3-b04e-ca6d2504bb1d",
   "metadata": {},
   "source": [
    "A: This method involves analyzing word pairs (or tuples) that appear within a specified distance of each other more often than would be expected by chance. This concept is known as \"window-based collocation\". It can be implemented with NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de063f9d-c9dc-4e46-a60a-a6aadd462c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JACK said:\n",
      "  Personally, darling, to speak quite candidly, I don't much care about the name of Ernest ...I don't think the name suits me at all.\n",
      "  [Picking up the muffin-dish.] Oh, that is nonsense; you are always talking nonsense.\n",
      "  [In a pathetic voice.] Miss Prism, more is restored to you than this hand-bag. I was the baby you placed in it.\n",
      "  [Embracing her.] Yes ...mother!\n",
      "  Unmarried! I do not deny that is a serious blow. But after all, who has the right to cast a stone against one who has suffered? Cannot repentance wipe out an act of folly? Why should there be one law for men, and another for women? Mother, I forgive you. [Tries to embrace her again.]\n",
      "  [After a pause.] Lady Bracknell, I hate to seem inquisitive, but would you kindly inform me who I am?\n",
      "  Algy's elder brother! Then I have a brother after all. I knew I had a brother! I always said I had a brother! Cecily,--how could you have ever doubted that I had a brother? [Seizes hold of Algernon.] Dr. Chasuble, my unfortunate brother. Miss Prism, my unfortunate brother. Gwendolen, my unfortunate brother. Algy, you young scoundrel, you will have to treat me with more respect in the future. You have never behaved to me like a brother in all your life.\n",
      "  Good heavens! ...I had quite forgotten that point. Your decision on the subject of my name is irrevocable, I suppose?\n",
      "  Then the question had better be cleared up at once. Aunt Augusta, a moment. At the time when Miss Prism left me in the hand-bag, had I been christened already?\n",
      "  Then I was christened! That is settled. Now, what name was I given? Let me know the worst.\n",
      "\n",
      "\n",
      "GWENDOLEN said:\n",
      "  Mamma!  [He tries to rise; she restrains him.] I must beg you to retire. This is no place for you. Besides, Mr. Worthing has not quite finished yet.\n",
      "  I am engaged to Mr. Worthing, mamma. [They rise together.]\n",
      "  Cecily Cardew? [Moving to her and shaking hands.] What a very sweet name! Something tells me that we are going to be great friends. I like you already more than I can say. My first impressions of people are never wrong.\n",
      "  [Still standing up.] I may call you Cecily, may I not?\n",
      "  And you will always call me Gwendolen, won't you?\n",
      "  Then that is all quite settled, is it not?\n",
      "  Perhaps this might be a favourable opportunity for my mentioning who I am. My father is Lord Bracknell. You have never heard of papa, I suppose?\n",
      "  Outside the family circle, papa, I am glad to say, is entirely unknown. I think that is quite as it should be. The home seems to me to be the proper sphere for the man. And certainly, once a man begins to neglect his domestic duties he becomes painfully effeminate, does he not? And I don't like that. It makes men so very attractive. Cecily, mamma, whose views on education are remarkably strict, has brought me up to be extremely short-sighted; it is part of her system; so do you mind my looking at you through my glasses?\n",
      "  [After examining Cecily carefully through a lorgnette.] You are here on a short visit, I suppose.\n",
      "  Indeed?\n",
      "  Your guardian?\n",
      "  Oh! It is strange he never mentioned to me that he had a ward. How secretive of him! He grows more interesting hourly. I am not sure, however, that the news inspires me with feelings of unmixed delight. [Rising and going to her.] I am very fond of you, Cecily; I have liked you ever since I met you! But I am bound to state that now that I know that you are Mr. Worthing's ward, I cannot help expressing a wish you were--well, just a little older than you seem to be--and not quite so very alluring in appearance. In fact, if I may speak candidly--\n",
      "  Well, to speak with perfect candour, Cecily, I wish that you were fully forty-two, and more than usually plain for your age. Ernest has a strong upright nature. He is the very soul of truth and honour. Disloyalty would be as impossible to him as deception. But even men of the noblest possible moral character are extremely susceptible to the influence of the physical charms of others. Modern, no less than Ancient History, supplies us with many most painful examples of what I refer to. If it were not so, indeed, History would be quite unreadable.\n",
      "  Yes.\n",
      "  [Sitting down again.] Ernest never mentioned to me that he had a brother.\n",
      "  Ah! that accounts for it. And now that I think of it I have never heard any man mention his brother. The subject seems distasteful to most men. Cecily, you have lifted a load from my mind. I was growing almost anxious. It would have been terrible if any cloud had come across a friendship like ours, would it not? Of course you are quite, quite sure that it is not Mr. Ernest Worthing who is your guardian?\n",
      "  [Inquiringly.] I beg your pardon?\n",
      "  [Quite politely, rising.] My darling Cecily, I think there must be some slight error. Mr. Ernest Worthing is engaged to me. The announcement will appear in the _Morning Post_ on Saturday at the latest.\n",
      "  [Examines diary through her lorgnettte carefully.] It is certainly very curious, for he asked me to be his wife yesterday afternoon at 5.30. If you would care to verify the incident, pray do so.\n",
      "  The fact that they did not follow us at once into the house, as anyone else would have done, seems to me to show that they have some sense of shame left.\n",
      "  [After a pause.] They don't seem to notice us at all. Couldn't you cough?\n",
      "  They're looking at us. What effrontery!\n",
      "  Let us preserve a dignified silence.\n",
      "  This dignified silence seems to produce an unpleasant effect.\n",
      "  But we will not be the first to speak.\n",
      "  Mr. Worthing, I have something very particular to ask you. Much depends on your reply.\n",
      "  Yes, dear, if you can believe him.\n",
      "  True. In matters of grave importance, style, not sincerity is the vital thing. Mr. Worthing, what explanation can you offer to me for pretending to have a brother?  Was it in order that you might have an opportunity of coming up to town to see me as often as possible?\n",
      "\n",
      "\n",
      "ALGERNON said:\n",
      "  Cecily!\n",
      "  Oh, do let me read them, Cecily?\n",
      "  But was our engagement ever broken off?\n",
      "  But why on earth did you break it off?  What had I done?  I had done nothing at all. Cecily, I am very much hurt indeed to hear you broke it off. Particularly when the weather was so charming.\n",
      "  [Crossing to her, and kneeling.] What a perfect angel you are, Cecily.\n",
      "  Yes, darling, with a little help from others.\n",
      "  You'll never break off our engagement again, Cecily?\n",
      "  Yes, of course. [Nervously.]\n",
      "  But, my dear child, do you mean to say you could not love me if I had some other name?\n",
      "  Oh, any name you like--Algernon--for instance ...\n",
      "  Well, my own dear, sweet, loving little darling, I really can't see why you should object to the name of Algernon. It is not at all a bad name. In fact, it is rather an aristocratic name. Half of the chaps who get into the Bankruptcy Court are called Algernon. But seriously, Cecily ...[Moving to her] ...if my name was Algy, couldn't you love me?\n",
      "  Ahem!  Cecily!  [Picking up hat.] Your Rector here is, I suppose, thoroughly experienced in the practice of all the rites and ceremonials of the Church?\n",
      "  I shan't be away more than half an hour.\n",
      "  I'll be back in no time. -- [Kisses her and rushes down the garden.]\n",
      "  In order that I might have an opportunity of meeting you.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import defaultdict, deque\n",
    "\n",
    "file_path = '../data/1895_wilde-oscar_the-importance-of-being-earnest.txt'\n",
    "\n",
    "def filter_dialogues(text, characters):\n",
    "    # Regex to match character lines\n",
    "    pattern = r'^([A-Z]{2,}):(.*)$'\n",
    "    dialogue = defaultdict(list)\n",
    "    active_dialogue = []\n",
    "    last_speaker = None\n",
    "\n",
    "    # Use a deque to check the rolling set of speakers\n",
    "    speaker_window = deque(maxlen=3)\n",
    "\n",
    "    for line in text.split('\\n'):\n",
    "        match = re.match(pattern, line.strip())\n",
    "        if match:\n",
    "            speaker, speech = match.groups()\n",
    "            if speaker in characters:\n",
    "                # Check the continuity of the conversation among the three\n",
    "                if last_speaker and last_speaker != speaker:\n",
    "                    speaker_window.append(speaker)\n",
    "                    # When we have three unique speakers in the window\n",
    "                    if len(speaker_window) == 3 and len(set(speaker_window)) == 3:\n",
    "                        # Confirm all targeted characters are part of the conversation\n",
    "                        if all(char in speaker_window for char in characters):\n",
    "                            active_dialogue.append((speaker, speech.strip()))\n",
    "                else:\n",
    "                    # Reset if the speaker repeats before cycling through the three\n",
    "                    active_dialogue = [(speaker, speech.strip())]\n",
    "                last_speaker = speaker\n",
    "            else:\n",
    "                # Reset everything if a non-target speaks\n",
    "                last_speaker = None\n",
    "                active_dialogue = []\n",
    "                speaker_window.clear()\n",
    "        elif active_dialogue:\n",
    "            # If there's a break in dialogue (e.g., a direction line or empty line), commit the active dialogue\n",
    "            for spkr, spch in active_dialogue:\n",
    "                dialogue[spkr].append(spch)\n",
    "            active_dialogue = []\n",
    "            speaker_window.clear()\n",
    "\n",
    "    return dialogue\n",
    "\n",
    "# Specifying the target characters\n",
    "target_characters = {'ALGERNON', 'JACK', 'GWENDOLEN'}\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "filtered_dialogues = filter_dialogues(text, target_characters)\n",
    "\n",
    "for character, speeches in filtered_dialogues.items():\n",
    "    print(f\"{character} said:\")\n",
    "    for speech in speeches:\n",
    "        print(f\"  {speech}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c199869-2fbe-4598-8add-c16c62253d69",
   "metadata": {},
   "source": [
    "### Q: How can I calculate the amount of speech in a play per character (either number of words or percentage of the whole text that a certain character speaks)?  And is there a way to analyze speech spoken by a single character or to compare the speech of specific characters?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57c3dd0-73a7-491c-adfc-f754437b7cb2",
   "metadata": {},
   "source": [
    "A: To do this we need to retrieve all characters and their associated lines, then  count those lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71daad4a-9dbe-4952-9599-eb0a9b5e9535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Counts Per Character: {'JACK': 356, 'GWENDOLEN': 508, 'CECILY': 562, 'ALGERNON': 368, 'MERRIMAN': 35}\n",
      "Word Percentages Per Character: {'JACK': 19.464188080918536, 'GWENDOLEN': 27.7747402952433, 'CECILY': 30.727173318753415, 'ALGERNON': 20.12028430836523, 'MERRIMAN': 1.913613996719519}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/tomvannuenen/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/tomvannuenen/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Initialize tokenizer and stopwords\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "file_path = '../data/1895_wilde-oscar_the-importance-of-being-earnest.txt'\n",
    "\n",
    "def parse_play(text):\n",
    "    # Regex to match lines indicating a speaker, such as 'ALGERNON:'\n",
    "    pattern = r'^([A-Z]{2,}):(.*)$'\n",
    "    character_speech = defaultdict(list)\n",
    "    \n",
    "    for line in text.split('\\n'):\n",
    "        match = re.match(pattern, line.strip())\n",
    "        if match:\n",
    "            character, speech = match.groups()\n",
    "            character_speech[character].append(speech.strip())\n",
    "    \n",
    "    return character_speech\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "character_speech = parse_play(text)\n",
    "\n",
    "# Calculating the number of words spoken by each character minus stopwords and punctuation\n",
    "character_word_counts = {\n",
    "    char: sum(len([word for word in tokenizer.tokenize(speech.lower()) if word not in stop_words])\n",
    "              for speech in speeches) \n",
    "    for char, speeches in character_speech.items()\n",
    "}\n",
    "\n",
    "total_words = sum(character_word_counts.values())\n",
    "character_word_percentage = {char: (count / total_words * 100) for char, count in character_word_counts.items()}\n",
    "\n",
    "print(\"Word Counts Per Character:\", character_word_counts)\n",
    "print(\"Word Percentages Per Character:\", character_word_percentage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddb87351-f507-400c-9b94-5dcf0c90c88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common words used by Algernon: [('cecily', 11), ('muffins', 9), ('name', 7), ('jack', 5), ('like', 5), ('eat', 5), ('one', 5), ('tea', 5), ('love', 4), ('yes', 4)]\n"
     ]
    }
   ],
   "source": [
    "# Analysis of Algernon's speech\n",
    "algernon_speech = ' '.join(character_speech['ALGERNON'])\n",
    "algernon_words = [word for word in tokenizer.tokenize(algernon_speech.lower()) if word not in stop_words]\n",
    "algernon_word_freq = Counter(algernon_words)\n",
    "\n",
    "algernon_common_words = algernon_word_freq.most_common(10)\n",
    "print(\"Most common words used by Algernon:\", algernon_common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d4f15fb-31f5-422d-a70a-a20307dff736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinctive words used by Algernon: {'thing', 'till', 'dish', 'must', 'passionately', 'away', 'taken', 'practice', 'garden', 'beauty', 'perfectly', 'food', 'dear', 'muffins', 'eating', 'possible', 'settled', 'cake', 'oh', 'christening', 'talk', 'shakes', 'devotedly', 'chasuble', 'deceiving', 'takes', 'butter', 'bad', 'experienced', 'written', 'three', 'hopelessly', 'chair', 'jack', 'best', 'court', 'old', 'lady', 'next', 'though', 'marry', 'probably', 'hat', 'intimately', 'read', 'could', 'church', 'stock', 'moving', 'heartless', 'speaking', 'week', 'round', 'particularly', 'rites', 'simply', 'finished', 'everything', 'possibly', 'back', 'hereditary', 'actually', 'continues', 'broken', 'present', 'keep', 'agitated', 'bankruptcy', 'charming', 'give', 'drink', 'vulgar', 'instance', 'done', 'anybody', 'served', 'kisses', 'go', 'looked', 'angel', 'engaged', 'really', 'world', 'way', 'absurd', 'christened', 'fairfax', 'hospitality', 'miss', 'dared', 'except', 'yet', 'likelihood', 'broke', 'object', 'engagement', 'besides', 'help', 'rather', 'people', 'tea', 'instead', 'first', 'wanted', 'like', 'important', 'begins', 'picking', 'however', 'six', 'rushes', 'told', 'others', 'algernon', 'see', 'chaps', 'refuse', 'meeting', 'dr', 'diary', 'look', 'name', 'united', 'rising', 'made', 'let', 'left', 'aback', 'aristocratic', 'thoroughly', 'since', 'muffin', 'much', 'crossing', 'suppose', 'nothing', 'incomparable', 'brilliant', 'cecily', 'quite', 'fond', 'come', 'hour', 'arrangements', 'ceremonials', 'earth', 'order', 'ernest', 'wildly', 'consoles', 'years', 'parties', 'upon', 'think', 'pretty', 'time', 'course', 'mean', 'vegetarians', 'still', 'yes', 'clever', 'groans', 'break', 'darling', 'said', 'wonderful', 'half', 'sweet', 'severe', 'never', 'perfect', 'tell', 'loving', 'dinner', 'moment', 'guests', 'would', 'merely', 'opportunity', 'eat', 'ask', 'day', 'one', 'allow', 'great', 'well', 'last', 'admit', 'calmly', 'whole', 'might', 'defence', 'rector', 'become', 'kneeling', 'knows', 'indeed', 'always', 'fact', 'quarter', 'seriously', 'ahem', 'months', 'weather', 'rapidly', 'child', 'letters', 'business', 'cousin', 'without', 'sinks', 'cuffs', 'brokers', 'say', 'seizes', 'love', 'called', 'offering', 'unhappy', 'wish', 'manner', 'nervously', 'may', 'chill', 'get', 'two', 'young', 'little', 'trouble', 'ideas', 'anything', 'ever', 'algy', 'adore', 'hear', 'somewhat', 'care', 'hurt', 'hands', 'boy'}\n",
      "Distinctive words used by Lane: set()\n"
     ]
    }
   ],
   "source": [
    "# Comparison of Algernon's and Lane's speech\n",
    "lane_speech = ' '.join(character_speech['LANE'])\n",
    "lane_words = [word for word in tokenizer.tokenize(lane_speech.lower()) if word not in stop_words]\n",
    "lane_word_freq = Counter(lane_words)\n",
    "\n",
    "# Very basic way to count \"distinctive\" is by checking if a word is used more by one character compared to another\n",
    "distinctive_algernon = {word for word in algernon_word_freq if algernon_word_freq[word] > lane_word_freq.get(word, 0)}\n",
    "distinctive_lane = {word for word in lane_word_freq if lane_word_freq[word] > algernon_word_freq.get(word, 0)}\n",
    "\n",
    "print(\"Distinctive words used by Algernon:\", distinctive_algernon)\n",
    "print(\"Distinctive words used by Lane:\", distinctive_lane)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40a766c-2fc2-43fd-bcee-2e09fd2a9a61",
   "metadata": {},
   "source": [
    "### Q: How can I track the mirroring of language in a text (ex: when characters are in conversation and repeat similar words back to each other vs. when specific discussions have a large variance of words)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef7ac1f-4b30-48f8-80f4-a3b9056faa63",
   "metadata": {},
   "source": [
    "A: For Lexical Similarity, we can use Jaccard Similarity, which measures the similarity between two sets; or cosine Similarity, which uses the count of words (vector space model) to measure the cosine of the angle between two vectors -- this could be useful for longer texts.\n",
    "\n",
    "For Lexical Diversity (Variance), we can use Type-Token Ratio (TTR): The ratio of unique words (types) to the total number of words (tokens) in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ed42936-f4ab-40fa-8cb5-53c9ce26f004",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/tomvannuenen/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/tomvannuenen/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict, deque\n",
    "import re\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Define characters\n",
    "characters = ['ALGERNON', 'JACK', 'GWENDOLEN', 'CECILY']\n",
    "\n",
    "# Reading the play text\n",
    "file_path = '../data/1895_wilde-oscar_the-importance-of-being-earnest.txt'\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Function to parse the play into dialogues by characters\n",
    "def parse_dialogues(text):\n",
    "    pattern = r'^([A-Z]{2,}):(.*)$'\n",
    "    dialogues = defaultdict(deque)  # Using deque for efficient pop and append operations\n",
    "    current_speaker = None\n",
    "    current_dialogue = []\n",
    "\n",
    "    for line in text.split('\\n'):\n",
    "        match = re.match(pattern, line.strip())\n",
    "        if match:\n",
    "            speaker, words = match.groups()\n",
    "            if speaker in characters:\n",
    "                if speaker != current_speaker and current_speaker is not None:\n",
    "                    dialogues[current_speaker].append(' '.join(current_dialogue))\n",
    "                    current_dialogue = []\n",
    "                current_speaker = speaker\n",
    "            words = word_tokenize(words)\n",
    "            current_dialogue.extend(words)\n",
    "        elif current_speaker:\n",
    "            dialogues[current_speaker].append(' '.join(current_dialogue))\n",
    "            current_dialogue = []\n",
    "            current_speaker = None\n",
    "\n",
    "    if current_dialogue:\n",
    "        dialogues[current_speaker].append(' '.join(current_dialogue))\n",
    "\n",
    "    return dialogues\n",
    "\n",
    "dialogues = parse_dialogues(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02ab83c4-995a-4368-a4a4-d6e0df330a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Character: JACK\n",
      "Dialogue 1 & 2 Jaccard Similarity: 0.69\n",
      "Dialogue 1 Type-Token Ratio: 0.77\n",
      "Dialogue 2 & 3 Jaccard Similarity: 0.72\n",
      "Dialogue 2 Type-Token Ratio: 0.75\n",
      "Dialogue 3 & 4 Jaccard Similarity: 0.53\n",
      "Dialogue 3 Type-Token Ratio: 0.77\n",
      "Dialogue 4 & 5 Jaccard Similarity: 0.48\n",
      "Dialogue 4 Type-Token Ratio: 0.74\n",
      "Dialogue 5 & 6 Jaccard Similarity: 0.29\n",
      "Dialogue 5 Type-Token Ratio: 1.00\n",
      "Dialogue 6 & 7 Jaccard Similarity: 0.24\n",
      "Dialogue 6 Type-Token Ratio: 1.00\n",
      "Dialogue 7 & 8 Jaccard Similarity: 0.44\n",
      "Dialogue 7 Type-Token Ratio: 0.91\n",
      "Dialogue 8 & 9 Jaccard Similarity: 0.56\n",
      "Dialogue 8 Type-Token Ratio: 1.00\n",
      "Dialogue 9 & 10 Jaccard Similarity: 0.50\n",
      "Dialogue 9 Type-Token Ratio: 0.94\n",
      "Dialogue 10 & 11 Jaccard Similarity: 0.56\n",
      "Dialogue 10 Type-Token Ratio: 1.00\n",
      "Dialogue 11 & 12 Jaccard Similarity: 0.54\n",
      "Dialogue 11 Type-Token Ratio: 0.81\n",
      "Dialogue 12 & 13 Jaccard Similarity: 0.58\n",
      "Dialogue 12 Type-Token Ratio: 1.00\n",
      "Dialogue 13 & 14 Jaccard Similarity: 0.61\n",
      "Dialogue 13 Type-Token Ratio: 1.00\n",
      "Dialogue 14 & 15 Jaccard Similarity: 0.79\n",
      "Dialogue 14 Type-Token Ratio: 0.91\n",
      "Dialogue 15 & 16 Jaccard Similarity: 0.61\n",
      "Dialogue 15 Type-Token Ratio: 1.00\n",
      "Dialogue 16 & 17 Jaccard Similarity: 0.56\n",
      "Dialogue 16 Type-Token Ratio: 0.82\n",
      "Dialogue 17 & 18 Jaccard Similarity: 0.78\n",
      "Dialogue 17 Type-Token Ratio: 0.88\n",
      "Dialogue 18 & 19 Jaccard Similarity: 0.65\n",
      "Dialogue 18 Type-Token Ratio: 0.95\n",
      "Dialogue 19 & 20 Jaccard Similarity: 0.41\n",
      "Dialogue 19 Type-Token Ratio: 1.00\n",
      "Dialogue 20 & 21 Jaccard Similarity: 0.57\n",
      "Dialogue 20 Type-Token Ratio: 0.66\n",
      "Dialogue 21 & 22 Jaccard Similarity: 0.68\n",
      "Dialogue 21 Type-Token Ratio: 0.93\n",
      "Dialogue 22 & 23 Jaccard Similarity: 0.81\n",
      "Dialogue 22 Type-Token Ratio: 0.81\n",
      "Dialogue 23 & 24 Jaccard Similarity: 0.71\n",
      "Dialogue 23 Type-Token Ratio: 0.88\n",
      "Dialogue 24 & 25 Jaccard Similarity: 0.32\n",
      "Dialogue 24 Type-Token Ratio: 0.89\n",
      "Dialogue 25 & 26 Jaccard Similarity: 0.32\n",
      "Dialogue 25 Type-Token Ratio: 1.00\n",
      "Dialogue 26 & 27 Jaccard Similarity: 0.29\n",
      "Dialogue 26 Type-Token Ratio: 0.65\n",
      "Dialogue 27 & 28 Jaccard Similarity: 0.45\n",
      "Dialogue 27 Type-Token Ratio: 1.00\n",
      "Dialogue 28 & 29 Jaccard Similarity: 0.81\n",
      "Dialogue 28 Type-Token Ratio: 0.89\n",
      "Dialogue 29 & 30 Jaccard Similarity: 0.53\n",
      "Dialogue 29 Type-Token Ratio: 0.89\n",
      "Dialogue 30 & 31 Jaccard Similarity: 0.49\n",
      "Dialogue 30 Type-Token Ratio: 1.00\n",
      "Dialogue 31 & 32 Jaccard Similarity: 0.72\n",
      "Dialogue 31 Type-Token Ratio: 0.79\n",
      "Dialogue 32 & 33 Jaccard Similarity: 0.64\n",
      "Dialogue 32 Type-Token Ratio: 0.92\n",
      "Dialogue 33 & 34 Jaccard Similarity: 0.64\n",
      "Dialogue 33 Type-Token Ratio: 0.55\n",
      "Dialogue 34 & 35 Jaccard Similarity: 0.69\n",
      "Dialogue 34 Type-Token Ratio: 0.96\n",
      "Dialogue 35 & 36 Jaccard Similarity: 0.58\n",
      "Dialogue 35 Type-Token Ratio: 0.86\n",
      "\n",
      "Character: GWENDOLEN\n",
      "Dialogue 1 & 2 Jaccard Similarity: 0.62\n",
      "Dialogue 1 Type-Token Ratio: 0.70\n",
      "Dialogue 2 & 3 Jaccard Similarity: 0.36\n",
      "Dialogue 2 Type-Token Ratio: 0.74\n",
      "Dialogue 3 & 4 Jaccard Similarity: 0.39\n",
      "Dialogue 3 Type-Token Ratio: 1.00\n",
      "Dialogue 4 & 5 Jaccard Similarity: 0.58\n",
      "Dialogue 4 Type-Token Ratio: 0.81\n",
      "Dialogue 5 & 6 Jaccard Similarity: 0.58\n",
      "Dialogue 5 Type-Token Ratio: 0.75\n",
      "Dialogue 6 & 7 Jaccard Similarity: 0.52\n",
      "Dialogue 6 Type-Token Ratio: 0.86\n",
      "Dialogue 7 & 8 Jaccard Similarity: 0.45\n",
      "Dialogue 7 Type-Token Ratio: 1.00\n",
      "Dialogue 8 & 9 Jaccard Similarity: 0.60\n",
      "Dialogue 8 Type-Token Ratio: 0.86\n",
      "Dialogue 9 & 10 Jaccard Similarity: 0.70\n",
      "Dialogue 9 Type-Token Ratio: 0.76\n",
      "Dialogue 10 & 11 Jaccard Similarity: 0.67\n",
      "Dialogue 10 Type-Token Ratio: 0.86\n",
      "Dialogue 11 & 12 Jaccard Similarity: 0.57\n",
      "Dialogue 11 Type-Token Ratio: 0.93\n",
      "Dialogue 12 & 13 Jaccard Similarity: 0.68\n",
      "Dialogue 12 Type-Token Ratio: 0.88\n",
      "Dialogue 13 & 14 Jaccard Similarity: 0.57\n",
      "Dialogue 13 Type-Token Ratio: 0.88\n",
      "Dialogue 14 & 15 Jaccard Similarity: 0.57\n",
      "Dialogue 14 Type-Token Ratio: 0.92\n",
      "Dialogue 15 & 16 Jaccard Similarity: 0.41\n",
      "Dialogue 15 Type-Token Ratio: 0.91\n",
      "Dialogue 16 & 17 Jaccard Similarity: 0.66\n",
      "Dialogue 16 Type-Token Ratio: 0.93\n",
      "Dialogue 17 & 18 Jaccard Similarity: 0.64\n",
      "Dialogue 17 Type-Token Ratio: 0.70\n",
      "Dialogue 18 & 19 Jaccard Similarity: 0.67\n",
      "Dialogue 18 Type-Token Ratio: 0.90\n",
      "Dialogue 19 & 20 Jaccard Similarity: 0.18\n",
      "Dialogue 19 Type-Token Ratio: 0.88\n",
      "Dialogue 20 & 21 Jaccard Similarity: 0.31\n",
      "Dialogue 20 Type-Token Ratio: 1.00\n",
      "Dialogue 21 & 22 Jaccard Similarity: 0.20\n",
      "Dialogue 21 Type-Token Ratio: 1.00\n",
      "Dialogue 22 & 23 Jaccard Similarity: 0.76\n",
      "Dialogue 22 Type-Token Ratio: 0.66\n",
      "Dialogue 23 & 24 Jaccard Similarity: 0.11\n",
      "Dialogue 23 Type-Token Ratio: 0.71\n",
      "Dialogue 24 & 25 Jaccard Similarity: 0.18\n",
      "Dialogue 24 Type-Token Ratio: 1.00\n",
      "Dialogue 25 & 26 Jaccard Similarity: 0.44\n",
      "Dialogue 25 Type-Token Ratio: 0.94\n",
      "Dialogue 26 & 27 Jaccard Similarity: 0.45\n",
      "Dialogue 26 Type-Token Ratio: 0.74\n",
      "Dialogue 27 & 28 Jaccard Similarity: 0.49\n",
      "Dialogue 27 Type-Token Ratio: 1.00\n",
      "Dialogue 28 & 29 Jaccard Similarity: 0.66\n",
      "Dialogue 28 Type-Token Ratio: 0.88\n",
      "Dialogue 29 & 30 Jaccard Similarity: 0.59\n",
      "Dialogue 29 Type-Token Ratio: 0.90\n",
      "Dialogue 30 & 31 Jaccard Similarity: 0.60\n",
      "Dialogue 30 Type-Token Ratio: 0.86\n",
      "Dialogue 31 & 32 Jaccard Similarity: 0.60\n",
      "Dialogue 31 Type-Token Ratio: 0.90\n",
      "Dialogue 32 & 33 Jaccard Similarity: 0.50\n",
      "Dialogue 32 Type-Token Ratio: 1.00\n",
      "Dialogue 33 & 34 Jaccard Similarity: 0.73\n",
      "Dialogue 33 Type-Token Ratio: 1.00\n",
      "Dialogue 34 & 35 Jaccard Similarity: 0.62\n",
      "Dialogue 34 Type-Token Ratio: 1.00\n",
      "Dialogue 35 & 36 Jaccard Similarity: 0.52\n",
      "Dialogue 35 Type-Token Ratio: 1.00\n",
      "Dialogue 36 & 37 Jaccard Similarity: 0.64\n",
      "Dialogue 36 Type-Token Ratio: 0.94\n",
      "Dialogue 37 & 38 Jaccard Similarity: 0.65\n",
      "Dialogue 37 Type-Token Ratio: 0.90\n",
      "Dialogue 38 & 39 Jaccard Similarity: 0.67\n",
      "Dialogue 38 Type-Token Ratio: 0.79\n",
      "Dialogue 39 & 40 Jaccard Similarity: 0.47\n",
      "Dialogue 39 Type-Token Ratio: 0.80\n",
      "Dialogue 40 & 41 Jaccard Similarity: 0.44\n",
      "Dialogue 40 Type-Token Ratio: 0.90\n",
      "\n",
      "Character: CECILY\n",
      "Dialogue 1 & 2 Jaccard Similarity: 0.78\n",
      "Dialogue 1 Type-Token Ratio: 0.79\n",
      "Dialogue 2 & 3 Jaccard Similarity: 0.81\n",
      "Dialogue 2 Type-Token Ratio: 0.74\n",
      "Dialogue 3 & 4 Jaccard Similarity: 0.60\n",
      "Dialogue 3 Type-Token Ratio: 0.74\n",
      "Dialogue 4 & 5 Jaccard Similarity: 0.62\n",
      "Dialogue 4 Type-Token Ratio: 0.76\n",
      "Dialogue 5 & 6 Jaccard Similarity: 0.74\n",
      "Dialogue 5 Type-Token Ratio: 1.00\n",
      "Dialogue 6 & 7 Jaccard Similarity: 0.72\n",
      "Dialogue 6 Type-Token Ratio: 0.95\n",
      "Dialogue 7 & 8 Jaccard Similarity: 0.54\n",
      "Dialogue 7 Type-Token Ratio: 1.00\n",
      "Dialogue 8 & 9 Jaccard Similarity: 0.70\n",
      "Dialogue 8 Type-Token Ratio: 0.76\n",
      "Dialogue 9 & 10 Jaccard Similarity: 0.68\n",
      "Dialogue 9 Type-Token Ratio: 0.74\n",
      "Dialogue 10 & 11 Jaccard Similarity: 0.71\n",
      "Dialogue 10 Type-Token Ratio: 0.79\n",
      "Dialogue 11 & 12 Jaccard Similarity: 0.66\n",
      "Dialogue 11 Type-Token Ratio: 0.84\n",
      "Dialogue 12 & 13 Jaccard Similarity: 0.72\n",
      "Dialogue 12 Type-Token Ratio: 0.83\n",
      "Dialogue 13 & 14 Jaccard Similarity: 0.67\n",
      "Dialogue 13 Type-Token Ratio: 0.82\n",
      "Dialogue 14 & 15 Jaccard Similarity: 0.67\n",
      "Dialogue 14 Type-Token Ratio: 0.93\n",
      "Dialogue 15 & 16 Jaccard Similarity: 0.34\n",
      "Dialogue 15 Type-Token Ratio: 0.86\n",
      "Dialogue 16 & 17 Jaccard Similarity: 0.32\n",
      "Dialogue 16 Type-Token Ratio: 1.00\n",
      "Dialogue 17 & 18 Jaccard Similarity: 0.64\n",
      "Dialogue 17 Type-Token Ratio: 0.83\n",
      "Dialogue 18 & 19 Jaccard Similarity: 0.26\n",
      "Dialogue 18 Type-Token Ratio: 0.81\n",
      "Dialogue 19 & 20 Jaccard Similarity: 0.39\n",
      "Dialogue 19 Type-Token Ratio: 1.00\n",
      "Dialogue 20 & 21 Jaccard Similarity: 0.53\n",
      "Dialogue 20 Type-Token Ratio: 1.00\n",
      "Dialogue 21 & 22 Jaccard Similarity: 0.62\n",
      "Dialogue 21 Type-Token Ratio: 0.76\n",
      "Dialogue 22 & 23 Jaccard Similarity: 0.11\n",
      "Dialogue 22 Type-Token Ratio: 0.86\n",
      "Dialogue 23 & 24 Jaccard Similarity: 0.06\n",
      "Dialogue 23 Type-Token Ratio: 1.00\n",
      "Dialogue 24 & 25 Jaccard Similarity: 0.62\n",
      "Dialogue 24 Type-Token Ratio: 0.83\n",
      "Dialogue 25 & 26 Jaccard Similarity: 0.60\n",
      "Dialogue 25 Type-Token Ratio: 0.87\n",
      "Dialogue 26 & 27 Jaccard Similarity: 0.63\n",
      "Dialogue 26 Type-Token Ratio: 0.82\n",
      "Dialogue 27 & 28 Jaccard Similarity: 0.50\n",
      "Dialogue 27 Type-Token Ratio: 0.82\n",
      "Dialogue 28 & 29 Jaccard Similarity: 0.61\n",
      "Dialogue 28 Type-Token Ratio: 0.72\n",
      "Dialogue 29 & 30 Jaccard Similarity: 0.66\n",
      "Dialogue 29 Type-Token Ratio: 0.83\n",
      "Dialogue 30 & 31 Jaccard Similarity: 0.42\n",
      "Dialogue 30 Type-Token Ratio: 0.96\n",
      "Dialogue 31 & 32 Jaccard Similarity: 0.26\n",
      "Dialogue 31 Type-Token Ratio: 1.00\n",
      "Dialogue 32 & 33 Jaccard Similarity: 0.42\n",
      "Dialogue 32 Type-Token Ratio: 1.00\n",
      "Dialogue 33 & 34 Jaccard Similarity: 0.40\n",
      "Dialogue 33 Type-Token Ratio: 0.87\n",
      "Dialogue 34 & 35 Jaccard Similarity: 0.37\n",
      "Dialogue 34 Type-Token Ratio: 1.00\n",
      "Dialogue 35 & 36 Jaccard Similarity: 0.52\n",
      "Dialogue 35 Type-Token Ratio: 0.88\n",
      "Dialogue 36 & 37 Jaccard Similarity: 0.62\n",
      "Dialogue 36 Type-Token Ratio: 1.00\n",
      "Dialogue 37 & 38 Jaccard Similarity: 0.61\n",
      "Dialogue 37 Type-Token Ratio: 0.81\n",
      "Dialogue 38 & 39 Jaccard Similarity: 0.61\n",
      "Dialogue 38 Type-Token Ratio: 0.85\n",
      "Dialogue 39 & 40 Jaccard Similarity: 0.50\n",
      "Dialogue 39 Type-Token Ratio: 1.00\n",
      "Dialogue 40 & 41 Jaccard Similarity: 0.63\n",
      "Dialogue 40 Type-Token Ratio: 0.95\n",
      "Dialogue 41 & 42 Jaccard Similarity: 0.66\n",
      "Dialogue 41 Type-Token Ratio: 0.92\n",
      "Dialogue 42 & 43 Jaccard Similarity: 0.64\n",
      "Dialogue 42 Type-Token Ratio: 0.78\n",
      "Dialogue 43 & 44 Jaccard Similarity: 0.57\n",
      "Dialogue 43 Type-Token Ratio: 1.00\n",
      "Dialogue 44 & 45 Jaccard Similarity: 0.59\n",
      "Dialogue 44 Type-Token Ratio: 0.89\n",
      "Dialogue 45 & 46 Jaccard Similarity: 0.76\n",
      "Dialogue 45 Type-Token Ratio: 0.84\n",
      "Dialogue 46 & 47 Jaccard Similarity: 0.61\n",
      "Dialogue 46 Type-Token Ratio: 0.84\n",
      "Dialogue 47 & 48 Jaccard Similarity: 0.46\n",
      "Dialogue 47 Type-Token Ratio: 0.91\n",
      "Dialogue 48 & 49 Jaccard Similarity: 0.48\n",
      "Dialogue 48 Type-Token Ratio: 1.00\n",
      "Dialogue 49 & 50 Jaccard Similarity: 0.60\n",
      "Dialogue 49 Type-Token Ratio: 0.91\n",
      "Dialogue 50 & 51 Jaccard Similarity: 0.44\n",
      "Dialogue 50 Type-Token Ratio: 0.90\n",
      "Dialogue 51 & 52 Jaccard Similarity: 0.50\n",
      "Dialogue 51 Type-Token Ratio: 1.00\n",
      "Dialogue 52 & 53 Jaccard Similarity: 0.34\n",
      "Dialogue 52 Type-Token Ratio: 1.00\n",
      "Dialogue 53 & 54 Jaccard Similarity: 0.63\n",
      "Dialogue 53 Type-Token Ratio: 0.93\n",
      "Dialogue 54 & 55 Jaccard Similarity: 0.55\n",
      "Dialogue 54 Type-Token Ratio: 1.00\n",
      "Dialogue 55 & 56 Jaccard Similarity: 0.52\n",
      "Dialogue 55 Type-Token Ratio: 0.94\n",
      "\n",
      "Character: ALGERNON\n",
      "Dialogue 1 & 2 Jaccard Similarity: 0.28\n",
      "Dialogue 1 Type-Token Ratio: 0.89\n",
      "Dialogue 2 & 3 Jaccard Similarity: 0.50\n",
      "Dialogue 2 Type-Token Ratio: 0.80\n",
      "Dialogue 3 & 4 Jaccard Similarity: 0.23\n",
      "Dialogue 3 Type-Token Ratio: 0.82\n",
      "Dialogue 4 & 5 Jaccard Similarity: 0.23\n",
      "Dialogue 4 Type-Token Ratio: 1.00\n",
      "Dialogue 5 & 6 Jaccard Similarity: 0.55\n",
      "Dialogue 5 Type-Token Ratio: 0.72\n",
      "Dialogue 6 & 7 Jaccard Similarity: 0.35\n",
      "Dialogue 6 Type-Token Ratio: 0.68\n",
      "Dialogue 7 & 8 Jaccard Similarity: 0.43\n",
      "Dialogue 7 Type-Token Ratio: 1.00\n",
      "Dialogue 8 & 9 Jaccard Similarity: 0.58\n",
      "Dialogue 8 Type-Token Ratio: 1.00\n",
      "Dialogue 9 & 10 Jaccard Similarity: 0.52\n",
      "Dialogue 9 Type-Token Ratio: 1.00\n",
      "Dialogue 10 & 11 Jaccard Similarity: 0.47\n",
      "Dialogue 10 Type-Token Ratio: 0.93\n",
      "Dialogue 11 & 12 Jaccard Similarity: 0.52\n",
      "Dialogue 11 Type-Token Ratio: 0.89\n",
      "Dialogue 12 & 13 Jaccard Similarity: 0.30\n",
      "Dialogue 12 Type-Token Ratio: 0.90\n",
      "Dialogue 13 & 14 Jaccard Similarity: 0.60\n",
      "Dialogue 13 Type-Token Ratio: 1.00\n",
      "Dialogue 14 & 15 Jaccard Similarity: 0.67\n",
      "Dialogue 14 Type-Token Ratio: 0.78\n",
      "Dialogue 15 & 16 Jaccard Similarity: 0.61\n",
      "Dialogue 15 Type-Token Ratio: 0.89\n",
      "Dialogue 16 & 17 Jaccard Similarity: 0.48\n",
      "Dialogue 16 Type-Token Ratio: 0.91\n",
      "Dialogue 17 & 18 Jaccard Similarity: 0.43\n",
      "Dialogue 17 Type-Token Ratio: 1.00\n",
      "Dialogue 18 & 19 Jaccard Similarity: 0.44\n",
      "Dialogue 18 Type-Token Ratio: 0.89\n",
      "Dialogue 19 & 20 Jaccard Similarity: 0.61\n",
      "Dialogue 19 Type-Token Ratio: 0.91\n",
      "Dialogue 20 & 21 Jaccard Similarity: 0.54\n",
      "Dialogue 20 Type-Token Ratio: 0.92\n",
      "Dialogue 21 & 22 Jaccard Similarity: 0.67\n",
      "Dialogue 21 Type-Token Ratio: 0.73\n",
      "Dialogue 22 & 23 Jaccard Similarity: 0.49\n",
      "Dialogue 22 Type-Token Ratio: 0.85\n",
      "Dialogue 23 & 24 Jaccard Similarity: 0.58\n",
      "Dialogue 23 Type-Token Ratio: 0.79\n",
      "Dialogue 24 & 25 Jaccard Similarity: 0.61\n",
      "Dialogue 24 Type-Token Ratio: 1.00\n",
      "Dialogue 25 & 26 Jaccard Similarity: 0.57\n",
      "Dialogue 25 Type-Token Ratio: 0.95\n",
      "Dialogue 26 & 27 Jaccard Similarity: 0.66\n",
      "Dialogue 26 Type-Token Ratio: 0.94\n",
      "Dialogue 27 & 28 Jaccard Similarity: 0.62\n",
      "Dialogue 27 Type-Token Ratio: 0.80\n",
      "Dialogue 28 & 29 Jaccard Similarity: 0.67\n",
      "Dialogue 28 Type-Token Ratio: 0.95\n",
      "Dialogue 29 & 30 Jaccard Similarity: 0.74\n",
      "Dialogue 29 Type-Token Ratio: 0.80\n",
      "Dialogue 30 & 31 Jaccard Similarity: 0.68\n",
      "Dialogue 30 Type-Token Ratio: 0.84\n",
      "Dialogue 31 & 32 Jaccard Similarity: 0.67\n",
      "Dialogue 31 Type-Token Ratio: 0.67\n",
      "Dialogue 32 & 33 Jaccard Similarity: 0.61\n",
      "Dialogue 32 Type-Token Ratio: 0.74\n",
      "Dialogue 33 & 34 Jaccard Similarity: 0.56\n",
      "Dialogue 33 Type-Token Ratio: 1.00\n",
      "Dialogue 34 & 35 Jaccard Similarity: 0.47\n",
      "Dialogue 34 Type-Token Ratio: 0.80\n",
      "Dialogue 35 & 36 Jaccard Similarity: 0.58\n",
      "Dialogue 35 Type-Token Ratio: 0.83\n",
      "Dialogue 36 & 37 Jaccard Similarity: 0.36\n",
      "Dialogue 36 Type-Token Ratio: 1.00\n",
      "Dialogue 37 & 38 Jaccard Similarity: 0.35\n",
      "Dialogue 37 Type-Token Ratio: 1.00\n",
      "Dialogue 38 & 39 Jaccard Similarity: 0.58\n",
      "Dialogue 38 Type-Token Ratio: 1.00\n",
      "Dialogue 39 & 40 Jaccard Similarity: 0.60\n",
      "Dialogue 39 Type-Token Ratio: 0.75\n",
      "Dialogue 40 & 41 Jaccard Similarity: 0.56\n",
      "Dialogue 40 Type-Token Ratio: 0.96\n",
      "Dialogue 41 & 42 Jaccard Similarity: 0.58\n",
      "Dialogue 41 Type-Token Ratio: 0.88\n",
      "Dialogue 42 & 43 Jaccard Similarity: 0.61\n",
      "Dialogue 42 Type-Token Ratio: 1.00\n"
     ]
    }
   ],
   "source": [
    "def jaccard_similarity(doc1, doc2):\n",
    "    words_doc1 = set(doc1)\n",
    "    words_doc2 = set(doc2)\n",
    "    intersection = words_doc1.intersection(words_doc2)\n",
    "    union = words_doc1.union(words_doc2)\n",
    "    return float(len(intersection)) / len(union) if union else 0.0\n",
    "\n",
    "def type_token_ratio(text):\n",
    "    words = word_tokenize(text)\n",
    "    return len(set(words)) / len(words) if words else 0\n",
    "\n",
    "# Calculate similarity and diversity for each pair of consecutive dialogues\n",
    "for character, speeches in dialogues.items():\n",
    "    print(f\"\\nCharacter: {character}\")\n",
    "    for i in range(len(speeches) - 1):\n",
    "        sim = jaccard_similarity(speeches[i], speeches[i+1])\n",
    "        ttr = type_token_ratio(speeches[i])\n",
    "        print(f\"Dialogue {i+1} & {i+2} Jaccard Similarity: {sim:.2f}\")\n",
    "        print(f\"Dialogue {i+1} Type-Token Ratio: {ttr:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a329f457-8d0b-4d7a-ad4e-930cd1094c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dialogue between CECILY and ALGERNON:\n",
      " - CECILY to ALGERNON similarity: 0.042\n",
      " - CECILY TTR: 0.895, ALGERNON TTR: 0.800\n",
      " - CECILY to ALGERNON similarity: 0.091\n",
      " - CECILY TTR: 0.800, ALGERNON TTR: 0.824\n",
      " - CECILY to ALGERNON similarity: 0.034\n",
      " - CECILY TTR: 0.824, ALGERNON TTR: 1.000\n",
      " - CECILY to ALGERNON similarity: 0.040\n",
      " - CECILY TTR: 1.000, ALGERNON TTR: 0.649\n",
      " - CECILY to ALGERNON similarity: 0.111\n",
      " - CECILY TTR: 0.649, ALGERNON TTR: 1.000\n",
      " - CECILY to ALGERNON similarity: 0.083\n",
      " - CECILY TTR: 1.000, ALGERNON TTR: 1.000\n",
      " - CECILY to ALGERNON similarity: 0.062\n",
      " - CECILY TTR: 1.000, ALGERNON TTR: 1.000\n",
      " - CECILY to ALGERNON similarity: 0.045\n",
      " - CECILY TTR: 1.000, ALGERNON TTR: 0.867\n",
      " - CECILY to ALGERNON similarity: 0.120\n",
      " - CECILY TTR: 0.867, ALGERNON TTR: 0.833\n",
      "\n",
      "Dialogue between ALGERNON and CECILY:\n",
      " - ALGERNON to CECILY similarity: 0.165\n",
      " - ALGERNON TTR: 0.733, CECILY TTR: 0.744\n",
      " - ALGERNON to CECILY similarity: 0.152\n",
      " - ALGERNON TTR: 0.744, CECILY TTR: 0.727\n",
      " - ALGERNON to CECILY similarity: 0.077\n",
      " - ALGERNON TTR: 0.727, CECILY TTR: 0.947\n",
      " - ALGERNON to CECILY similarity: 0.160\n",
      " - ALGERNON TTR: 0.947, CECILY TTR: 1.000\n",
      " - ALGERNON to CECILY similarity: 0.056\n",
      " - ALGERNON TTR: 1.000, CECILY TTR: 0.753\n",
      " - ALGERNON to CECILY similarity: 0.165\n",
      " - ALGERNON TTR: 0.753, CECILY TTR: 0.727\n",
      " - ALGERNON to CECILY similarity: 0.174\n",
      " - ALGERNON TTR: 0.727, CECILY TTR: 0.776\n",
      " - ALGERNON to CECILY similarity: 0.169\n",
      " - ALGERNON TTR: 0.776, CECILY TTR: 0.816\n",
      " - ALGERNON to CECILY similarity: 0.000\n",
      " - ALGERNON TTR: 0.816, CECILY TTR: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/tomvannuenen/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/tomvannuenen/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Define characters\n",
    "characters = ['ALGERNON', 'JACK', 'GWENDOLEN', 'CECILY', 'LADY BRACKNELL', 'MISS PRISM', 'LANE', 'MERRIMAN']\n",
    "\n",
    "# Reading the play text\n",
    "file_path = '../data/1895_wilde-oscar_the-importance-of-being-earnest.txt'\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Function to parse the play into dialogues by characters\n",
    "def parse_dialogues(text):\n",
    "    pattern = r'^([A-Z ]+):\\s*(.*)$'\n",
    "    dialogues = defaultdict(list)  # Stores dialogues along with subsequent speaker\n",
    "    last_speaker = None\n",
    "\n",
    "    for line in text.split('\\n'):\n",
    "        match = re.match(pattern, line.strip())\n",
    "        if match:\n",
    "            speaker, words = match.groups()\n",
    "            speaker = speaker.strip()\n",
    "            if speaker in characters:\n",
    "                if last_speaker and last_speaker != speaker:\n",
    "                    dialogues[(last_speaker, speaker)].append(words)\n",
    "                last_speaker = speaker\n",
    "            else:\n",
    "                last_speaker = None  # Reset on non-character lines or scene changes\n",
    "        else:\n",
    "            last_speaker = None  # Ensures dialogues are between character changes\n",
    "\n",
    "    return dialogues\n",
    "\n",
    "dialogues = parse_dialogues(text)\n",
    "\n",
    "# Functions to calculate Jaccard similarity and Type-Token Ratio\n",
    "def jaccard_similarity(doc1, doc2):\n",
    "    words_doc1 = set(word_tokenize(doc1.lower()))\n",
    "    words_doc2 = set(word_tokenize(doc2.lower()))\n",
    "    intersection = words_doc1.intersection(words_doc2)\n",
    "    union = words_doc1.union(words_doc2)\n",
    "    return float(len(intersection)) / len(union) if union else 0.0\n",
    "\n",
    "def type_token_ratio(text):\n",
    "    words = word_tokenize(text.lower())\n",
    "    unique_words = set(words)\n",
    "    return len(unique_words) / len(words) if words else 0\n",
    "\n",
    "# Analyzing dialogues for similarity and diversity\n",
    "for pair, convo in dialogues.items():\n",
    "    if len(convo) > 1:  # Ensures there are at least two dialogues to compare\n",
    "        print(f\"\\nDialogue between {pair[0]} and {pair[1]}:\")\n",
    "        for i in range(len(convo) - 1):\n",
    "            sim = jaccard_similarity(convo[i], convo[i+1])\n",
    "            ttr1 = type_token_ratio(convo[i])\n",
    "            ttr2 = type_token_ratio(convo[i+1])\n",
    "            print(f\" - {pair[0]} to {pair[1]} similarity: {sim:.3f}\")\n",
    "            print(f\" - {pair[0]} TTR: {ttr1:.3f}, {pair[1]} TTR: {ttr2:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae8e747-be56-450b-9d57-e648990ec057",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
